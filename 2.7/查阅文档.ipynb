{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88cd17b3-a3b4-452e-bd76-7927a76356ed",
   "metadata": {},
   "source": [
    "实际上，上pytorch官网查询文档将会更加便捷"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b42061c7-dc57-4dcf-afbf-000718ce3dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ea2bf6f-e2f4-4ddf-9354-8b3b96861fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AbsTransform', 'AffineTransform', 'Bernoulli', 'Beta', 'Binomial', 'CatTransform', 'Categorical', 'Cauchy', 'Chi2', 'ComposeTransform', 'ContinuousBernoulli', 'CorrCholeskyTransform', 'CumulativeDistributionTransform', 'Dirichlet', 'Distribution', 'ExpTransform', 'Exponential', 'ExponentialFamily', 'FisherSnedecor', 'Gamma', 'Geometric', 'Gumbel', 'HalfCauchy', 'HalfNormal', 'Independent', 'IndependentTransform', 'InverseGamma', 'Kumaraswamy', 'LKJCholesky', 'Laplace', 'LogNormal', 'LogisticNormal', 'LowRankMultivariateNormal', 'LowerCholeskyTransform', 'MixtureSameFamily', 'Multinomial', 'MultivariateNormal', 'NegativeBinomial', 'Normal', 'OneHotCategorical', 'OneHotCategoricalStraightThrough', 'Pareto', 'Poisson', 'PositiveDefiniteTransform', 'PowerTransform', 'RelaxedBernoulli', 'RelaxedOneHotCategorical', 'ReshapeTransform', 'SigmoidTransform', 'SoftmaxTransform', 'SoftplusTransform', 'StackTransform', 'StickBreakingTransform', 'StudentT', 'TanhTransform', 'Transform', 'TransformedDistribution', 'Uniform', 'VonMises', 'Weibull', 'Wishart', '__all__', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', 'bernoulli', 'beta', 'biject_to', 'binomial', 'categorical', 'cauchy', 'chi2', 'constraint_registry', 'constraints', 'continuous_bernoulli', 'dirichlet', 'distribution', 'exp_family', 'exponential', 'fishersnedecor', 'gamma', 'geometric', 'gumbel', 'half_cauchy', 'half_normal', 'identity_transform', 'independent', 'inverse_gamma', 'kl', 'kl_divergence', 'kumaraswamy', 'laplace', 'lkj_cholesky', 'log_normal', 'logistic_normal', 'lowrank_multivariate_normal', 'mixture_same_family', 'multinomial', 'multivariate_normal', 'negative_binomial', 'normal', 'one_hot_categorical', 'pareto', 'poisson', 'register_kl', 'relaxed_bernoulli', 'relaxed_categorical', 'studentT', 'transform_to', 'transformed_distribution', 'transforms', 'uniform', 'utils', 'von_mises', 'weibull', 'wishart']\n"
     ]
    }
   ],
   "source": [
    "print(dir(torch.distributions)) # 所有函数和类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8015c83-d92e-4d45-bdaa-9020c181c457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function tensor in module torch:\n",
      "\n",
      "tensor(...)\n",
      "    tensor(data, *, dtype=None, device=None, requires_grad=False, pin_memory=False) -> Tensor\n",
      "    \n",
      "    Constructs a tensor with no autograd history (also known as a \"leaf tensor\", see :doc:`/notes/autograd`) by copying :attr:`data`.\n",
      "    \n",
      "    .. warning::\n",
      "    \n",
      "        When working with tensors prefer using :func:`torch.Tensor.clone`,\n",
      "        :func:`torch.Tensor.detach`, and :func:`torch.Tensor.requires_grad_` for\n",
      "        readability. Letting `t` be a tensor, ``torch.tensor(t)`` is equivalent to\n",
      "        ``t.clone().detach()``, and ``torch.tensor(t, requires_grad=True)``\n",
      "        is equivalent to ``t.clone().detach().requires_grad_(True)``.\n",
      "    \n",
      "    .. seealso::\n",
      "    \n",
      "        :func:`torch.as_tensor` preserves autograd history and avoids copies where possible.\n",
      "        :func:`torch.from_numpy` creates a tensor that shares storage with a NumPy array.\n",
      "    \n",
      "    Args:\n",
      "        data (array_like): Initial data for the tensor. Can be a list, tuple,\n",
      "            NumPy ``ndarray``, scalar, and other types.\n",
      "    \n",
      "    Keyword args:\n",
      "        dtype (:class:`torch.dtype`, optional): the desired data type of returned tensor.\n",
      "            Default: if ``None``, infers data type from :attr:`data`.\n",
      "        device (:class:`torch.device`, optional): the device of the constructed tensor. If None and data is a tensor\n",
      "            then the device of data is used. If None and data is not a tensor then\n",
      "            the result tensor is constructed on the current device.\n",
      "        requires_grad (bool, optional): If autograd should record operations on the\n",
      "            returned tensor. Default: ``False``.\n",
      "        pin_memory (bool, optional): If set, returned tensor would be allocated in\n",
      "            the pinned memory. Works only for CPU tensors. Default: ``False``.\n",
      "    \n",
      "    \n",
      "    Example::\n",
      "    \n",
      "        >>> torch.tensor([[0.1, 1.2], [2.2, 3.1], [4.9, 5.2]])\n",
      "        tensor([[ 0.1000,  1.2000],\n",
      "                [ 2.2000,  3.1000],\n",
      "                [ 4.9000,  5.2000]])\n",
      "    \n",
      "        >>> torch.tensor([0, 1])  # Type inference on data\n",
      "        tensor([ 0,  1])\n",
      "    \n",
      "        >>> torch.tensor([[0.11111, 0.222222, 0.3333333]],\n",
      "        ...              dtype=torch.float64,\n",
      "        ...              device=torch.device('cuda:0'))  # creates a double tensor on a CUDA device\n",
      "        tensor([[ 0.1111,  0.2222,  0.3333]], dtype=torch.float64, device='cuda:0')\n",
      "    \n",
      "        >>> torch.tensor(3.14159)  # Create a zero-dimensional (scalar) tensor\n",
      "        tensor(3.1416)\n",
      "    \n",
      "        >>> torch.tensor([])  # Create an empty tensor (of size (0,))\n",
      "        tensor([])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(torch.tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31edaa25-2752-4434-b9eb-b0d5846afb3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mInit signature:\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m/\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m     \n",
       "Built-in mutable sequence.\n",
       "\n",
       "If no argument is given, the constructor creates a new empty list.\n",
       "The argument must be an iterable if specified.\n",
       "\u001b[1;31mType:\u001b[0m           type\n",
       "\u001b[1;31mSubclasses:\u001b[0m     _HashedSeq, ParamSpec, _ConcatenateGenericAlias, StackSummary, _Threads, ConvertingList, DeferredConfigList, _ymd, SList, _ImmutableLineList, ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "list?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
